@inproceedings{ref_01_GoogleFL,
  title	= {Towards Federated Learning at Scale: System Design},
  author	= {K. A. Bonawitz and Hubert Eichner and Wolfgang Grieskamp and Dzmitry Huba and Alex Ingerman and Vladimir Ivanov and Chloé M Kiddon and Jakub Konečný and Stefano Mazzocchi and Brendan McMahan and Timon Van Overveldt and David Petrou and Daniel Ramage and Jason Roselander},
  year	= {2019},
  month={Mar. 31-Apr. 2},
  booktitle	= {2019 Systems and Machine Learning Conference (SysML)}
}



@article{ref_02_FLConcept,
  author = {Yang, Qiang and Liu, Yang and Chen, Tianjian and Tong, Yongxin},
  title = {Federated Machine Learning: Concept and Applications},
  year = {2019},
  issue_date = {February 2019},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  volume = {10},
  number = {2},
  issn = {2157-6904},
  journal = {ACM Transactions on Intelligent Systems and Technology},
  month = {Jan.},
  articleno = {12},
  numpages = {19}
}


@article{ref_03_FATE,
  title={Federated learning},
  author={Yang, Qiang and Liu, Yang and Cheng, Yong and Kang, Yan and Chen, Tianjian and Yu, Han},
  journal={Synthesis Lectures on Artificial Intelligence and Machine Learning},
  volume={13},
  number={3},
  pages={1--207},
  year={2019},
  month = {Dec.},
  publisher={Morgan \& Claypool Publishers}
}

@inproceedings{ref_04_model,
  title={Model poisoning attacks in federated learning},
  author={Bhagoji, Arjun Nitin and Chakraborty, Supriyo and Mittal, Prateek and Calo, Seraphin},
  booktitle={Proceedings of the 32nd Conference on Neural Information Processing Systems (NeurIPS)},
  year={2018},
  month= {Dec. 2-8}
}

@inproceedings{ref_05_model,
  title="Analyzing federated learning through an adversarial lens",
  author={Bhagoji, Arjun Nitin and Chakraborty, Supriyo and Mittal, Prateek and Calo, Seraphin},
  booktitle={Proceedings of the 36th International Conference on Machine Learning (ICML)},
  year={2019},
  month = {Jun. 9-15},
}



@inproceedings {ref_06_model,
author = {Minghong Fang and Xiaoyu Cao and Jinyuan Jia and Neil Gong},
title = {Local Model Poisoning Attacks to Byzantine-Robust Federated Learning},
booktitle = {29th {USENIX} Security Symposium ({USENIX} Security)},
year = {2020},
//isbn = {978-1-939133-17-5},
//pages = {1605--1622},
//url = {https://www.usenix.org/conference/usenixsecurity20/presentation/fang},
publisher = {{USENIX} Association},
month = {Aug. 12-14}
}


@InProceedings{ref_07_data,
  author =    {Battista Biggio and Blaine Nelson and Pavel Laskov},
  title =     {Poisoning Attacks against Support Vector Machines},
  booktitle = {Proceedings of the 29th International Conference on Machine Learning (ICML 2012)},
  //series =    {ICML '12},
  year =      {2012},
  //editor =    {John Langford and Joelle Pineau},
  //location =  {Edinburgh, Scotland, GB},
  //isbn =      {978-1-4503-1285-1},
  month =     {Jun. 26-Jul. 1},
  //publisher = {Omnipress},
  //address =   {New York, NY, USA},
  //pages=      {1807--1814}
}

@inproceedings{ref_08_data,
  author = {Nelson, Blaine and Barreno, Marco and Chi, Fuching Jack and Joseph, Anthony D. and Rubinstein, Benjamin I. P. and Saini, Udam and Sutton, Charles and Tygar, J. D. and Xia, Kai},
  title = {Exploiting Machine Learning to Subvert Your Spam Filter},
  year = {2008},
  //publisher = {USENIX Association},
  //address = {USA},
  //abstract = {Using statistical machine learning for making security decisions introduces new vulnerabilities in large scale systems. This paper shows how an adversary can exploit statistical machine learning, as used in the SpamBayes spam filter, to render it useless--even if the adversary's access is limited to only 1% of the training messages. We further demonstrate a new class of focused attacks that successfully prevent victims from receiving specific email messages. Finally, we introduce two new types of defenses against these attacks.},
  booktitle = {Proceedings of the 1st Usenix Workshop on Large-Scale Exploits and Emergent Threats},
  //articleno = {7},
  //numpages = {9},
  //location = {San Francisco, California},
  //series = {LEET'08},
  month={Apr. 14-15}
}


@InProceedings{ref_09_backdoor,
  title = 	 {How To Backdoor Federated Learning},
  author =       {Bagdasaryan, Eugene and Veit, Andreas and Hua, Yiqing and Estrin, Deborah and Shmatikov, Vitaly},
  booktitle = 	 {Proceedings of the 23rd International Conference on Artificial Intelligence and Statistics (AISTATS)},
  //pages = 	 {2938--2948},
  year = 	 {2020},
  //editor = 	 {Silvia Chiappa and Roberto Calandra},
  //volume = 	 {108},
  //series = 	 {Proceedings of Machine Learning Research},
  month = 	 {Aug. 26-28},
  //publisher =    {PMLR},
  //pdf = 	 {http://proceedings.mlr.press/v108/bagdasaryan20a/bagdasaryan20a.pdf},
  //url = 	 {
  http://proceedings.mlr.press/v108/bagdasaryan20a.html
  }
}

@article{ref_10_backdoor,
  title={Can you really backdoor federated learning?},
  author={Sun, Ziteng and Kairouz, Peter and Suresh, Ananda Theertha and McMahan, H Brendan},
  journal={arXiv preprint arXiv:1911.07963},
  year={2019},
  month = {Nov}
}


@inproceedings{ref_11_backdoor,
 author = {Wang, Hongyi and Sreenivasan, Kartik and Rajput, Shashank and Vishwakarma, Harit and Agarwal, Saurabh and Sohn, Jy-yong and Lee, Kangwook and Papailiopoulos, Dimitris},
 booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
 //editor = {H. Larochelle and M. Ranzato and R. Hadsell and M. F. Balcan and H. Lin},
 //pages = {16070--16084},
 publisher = {Curran Associates, Inc.},
 title = {Attack of the Tails: Yes, You Really Can Backdoor Federated Learning},
 //url = {https://proceedings.neurips.cc/paper/2020/file/b8ffa41d4e492f0fad2f13e29e1762eb-Paper.pdf},
 //volume = {33},
 year = {2020},
 month = {Dec. 6-12}
}


@inproceedings{ref_12_defense,
 author = {Blanchard, Peva and El Mhamdi, El Mahdi and Guerraoui, Rachid and Stainer, Julien},
 booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
 //editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 //pages = {},
 //publisher = {Curran Associates, Inc.},
 title = {Machine Learning with Adversaries: Byzantine Tolerant Gradient Descent},
 //url = {https://proceedings.neurips.cc/paper/2017/file/f4b9ec30ad9f68f89b29639786cb62ef-Paper.pdf},
 //volume = {30},
 year = {2017},
 month = {Dec. 4-9}
}


@InProceedings{ref_13_defense,
  title = 	 {{DRACO}: {B}yzantine-resilient Distributed Training via Redundant Gradients},
  author =       {Chen, Lingjiao and Wang, Hongyi and Charles, Zachary and Papailiopoulos, Dimitris},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning (ICML)},
  //pages = 	 {903--912},
  year = 	 {2018},
  //editor = 	 {Dy, Jennifer and Krause, Andreas},
  //volume = 	 {80},
  //series = 	 {Proceedings of Machine Learning Research},
  month = 	 {Jul. 10-15},
  //publisher =    {PMLR},
  //pdf = 	 {http://proceedings.mlr.press/v80/chen18l/chen18l.pdf},
  //url = 	 {http://proceedings.mlr.press/v80/chen18l.html},
  //abstract = 	 {Distributed model training is vulnerable to byzantine system failures and adversarial compute nodes, i.e., nodes that use malicious updates to corrupt the global model stored at a parameter server (PS). To guarantee some form of robustness, recent work suggests using variants of the geometric median as an aggregation rule, in place of gradient averaging. Unfortunately, median-based rules can incur a prohibitive computational overhead in large-scale settings, and their convergence guarantees often require strong assumptions. In this work, we present DRACO, a scalable framework for robust distributed training that uses ideas from coding theory. In DRACO, each compute node evaluates redundant gradients that are used by the parameter server to eliminate the effects of adversarial updates. DRACO comes with problem-independent robustness guarantees, and the model that it trains is identical to the one trained in the adversary-free setup. We provide extensive experiments on real datasets and distributed setups across a variety of large-scale models, where we show that DRACO is several times, to orders of magnitude faster than median-based approaches.}
}


@InProceedings{ref_14_defense,
author="Xie, Cong
and Koyejo, Oluwasanmi
and Gupta, Indranil",
//editor="Brefeld, Ulf
and Fromont, Elisa
and Hotho, Andreas
and Knobbe, Arno
and Maathuis, Marloes
and Robardet, C{\'e}line",
title="{SLSGD}: Secure and Efficient Distributed On-device Machine Learning",
booktitle="Machine Learning and Knowledge Discovery in Databases",
year="2020",
month="Sep. 14-18",
//publisher="Springer International Publishing",
//address="Cham",
//pages="213--228",
//abstract="We consider distributed on-device learning with limited communication and security requirements. We propose a new robust distributed optimization algorithm with efficient communication and attack tolerance. The proposed algorithm has provable convergence and robustness under non-IID settings. Empirical results show that the proposed algorithm stabilizes the convergence and tolerates data poisoning on a small number of workers.",
//isbn="978-3-030-46147-8"
}


@InProceedings{ref_15_defense,
  title = 	 {Zeno: Distributed Stochastic Gradient Descent with Suspicion-based Fault-tolerance},
  author =       {Xie, Cong and Koyejo, Sanmi and Gupta, Indranil},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning (ICML)},
  //pages = 	 {6893--6901},
  year = 	 {2019},
  //editor = 	 {Kamalika Chaudhuri and Ruslan Salakhutdinov},
  //volume = 	 {97},
  //series = 	 {Proceedings of Machine Learning Research},
  month = 	 {Jun. 9-15},
  //publisher =    {PMLR},
  //pdf = 	 {http://proceedings.mlr.press/v97/xie19b/xie19b.pdf},
  //url = 	 {
http://proceedings.mlr.press/v97/xie19b.html
},
  //abstract = 	 {We present Zeno, a technique to make distributed machine learning, particularly Stochastic Gradient Descent (SGD), tolerant to an arbitrary number of faulty workers. Zeno generalizes previous results that assumed a majority of non-faulty nodes; we need assume only one non-faulty worker. Our key idea is to suspect workers that are potentially defective. Since this is likely to lead to false positives, we use a ranking-based preference mechanism. We prove the convergence of SGD for non-convex problems under these scenarios. Experimental results show that Zeno outperforms existing approaches.}
}

@InProceedings{ref_16_defense,
  title = 	 {{B}yzantine-Robust Distributed Learning: Towards Optimal Statistical Rates},
  author =       {Yin, Dong and Chen, Yudong and Kannan, Ramchandran and Bartlett, Peter},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning (ICML)},
  //pages = 	 {5650--5659},
  year = 	 {2018},
  //editor = 	 {Dy, Jennifer and Krause, Andreas},
  //volume = 	 {80},
  //series = 	 {Proceedings of Machine Learning Research},
  month = 	 {Jul. 10-15},
  //publisher =    {PMLR},
  //pdf = 	 {http://proceedings.mlr.press/v80/yin18a/yin18a.pdf},
  //url = 	 {http://proceedings.mlr.press/v80/yin18a.html},
  //abstract = 	 {In this paper, we develop distributed optimization algorithms that are provably robust against Byzantine failures—arbitrary and potentially adversarial behavior, in distributed computing systems, with a focus on achieving optimal statistical performance. A main result of this work is a sharp analysis of two robust distributed gradient descent algorithms based on median and trimmed mean operations, respectively. We prove statistical error rates for all of strongly convex, non-strongly convex, and smooth non-convex population loss functions. In particular, these algorithms are shown to achieve order-optimal statistical error rates for strongly convex losses. To achieve better communication efficiency, we further propose a median-based distributed algorithm that is provably robust, and uses only one communication round. For strongly convex quadratic loss, we show that this algorithm achieves the same optimal error rate as the robust distributed gradient descent algorithms.}
}


@inproceedings{ref_17_defense,
author = {Cao, Xiaoyu and Fang, Minghong and Liu, Jia and Gong, Neil},
year = {2021},
month = {Feb. 21-25},
//pages = {},
booktitle={2021 Network and Distributed System Security Symposium (NDSS)},
title = {{FLTrust}: Byzantine-robust Federated Learning via Trust Bootstrapping},
//doi = {10.14722/ndss.2021.24434}
}

@inproceedings{ref_18_label_flipping,
  title={Understanding distributed poisoning attack in federated learning},
  author={Cao, Di and Chang, Shan and Lin, Zhijian and Liu, Guohua and Sun, Donghong},
  booktitle={2019 IEEE 25th International Conference on Parallel and Distributed Systems (ICPADS)},
  //pages={233--239},
  month = {Dec. 4-6},
  year={2019},
  //organization={IEEE},
  //doi={10.1109/ICPADS47876.2019.00042}
}

@inproceedings{ref_19_backdoor,
  title={Dba: Distributed backdoor attacks against federated learning},
  author={Xie, Chulin and Huang, Keli and Chen, Pin-Yu and Li, Bo},
  booktitle={7th International Conference on Learning Representations (ICLR)},
  year={2019},
  month           = {May 6-9}
}


@inproceedings{ref_20_ensemble,
  author={Tao Lin and Lingjing Kong and Sebastian U. Stich and Martin Jaggi},
  title={Ensemble Distillation for Robust Model Fusion in Federated Learning},
  year={2020},
  month           = {Dec. 6-12},
  cdate={1577836800000},
  booktitle={Proceedings of the 34th Conference on Neural Information Processing Systems (NeurIPS)}
}

@inproceedings{ref_21_ensemble_FedED,
  title={FedED: Federated Learning via Ensemble Distillation for Medical Relation Extraction},
  author={Sui, Dianbo and Chen, Yubo and Zhao, Jun and Jia, Yantao and Xie, Yuantao and Sun, Weijian},
  booktitle={Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  pages={2118--2128},
  year={2020},
  month           = {Nov. 16-20}
}




@inproceedings{ref_22_ensemble_FedBE,
title={FedBE: Making Bayesian Model Ensemble Applicable to Federated Learning},
author={Hong-You Chen and Wei-Lun Chao},
booktitle={International Conference on Learning Representations},
year={2021},
month           = {May 3-7},
url={https://openreview.net/forum?id=dgtpE6gKjHn}
}

@INPROCEEDINGS{ref_23_reputation,  
    author={S. {Chouikhi} and L. {Khoukhi} and S. {Ayed} and M. {Lemercier}},  
    booktitle={2020 IEEE 45th Conference on Local Computer Networks (LCN)}, title={An Efficient Reputation Management Model based on Game Theory for Vehicular Networks},   
    year={2020},  
    month           = {Nov. 16-19},
    volume={},  
    number={},  
    pages={413-416},  
    //doi={10.1109/LCN48667.2020.9314791}
}

@INPROCEEDINGS{ref_24_reputation,  
    author={Y. {Wen} and Y. {Huo} and T. {Jing} and Q. {Gao}},  booktitle={ICC 2020 - 2020 IEEE International Conference on Communications (ICC)},   
    title={A Reputation framework with Multiple-threshold Energy Detection in Wireless Cooperative Systems},   
    year={2020},  
    month           = {Jun. 7-11},
    volume={},  
    number={},  
    pages={1-6},  
    //doi={10.1109/ICC40277.2020.9149169}
}

@INPROCEEDINGS{ref_25_reputation,  
    author={K. {Lei} and Q. {Zhang} and L. {Xu} and Z. {Qi}},  booktitle={2018 IEEE 24th International Conference on Parallel and Distributed Systems (ICPADS)},   
    title={Reputation-Based Byzantine Fault-Tolerance for Consortium Blockchain},   
    year={2018},  
    month           = {Dec. 11-13},
    volume={},  
    number={},  
    pages={604-611},  
    //doi={10.1109/PADSW.2018.8644933}
}

@ARTICLE{ref_26_reputation,  
    author={P. {Kumari} and H. P. {Gupta} and T. {Dutta}},  
    journal={IEEE Transactions on Intelligent Transportation Systems},   title={A Bayesian Game Based Approach for Associating the Nodes to the Gateway in LoRa Network},   
    year={2021},  
    month           = {Jan.},
    volume={},  
    number={},  
    pages={1-10},  
    doi={10.1109/TITS.2020.3046302}
}

@ARTICLE{ref_27_reputation,  
    author={Liu, Guangchi and Yang, Qing and Wang, Honggang and Liu, Alex X.},  journal={IEEE Transactions on Dependable and Secure Computing},   title={Trust Assessment in Online Social Networks},   
    year={2021},  
    month           = {May},
    volume={18},  
    number={2},  
    pages={994-1007},  
    doi={10.1109/TDSC.2019.2916366}
}

@ARTICLE{ref_28_defense,  
  author={So, Jinhyun and Güler, Başak and Avestimehr, A. Salman},  
  journal={IEEE Journal on Selected Areas in Communications},   
  title={Byzantine-Resilient Secure Federated Learning},   
  year={2020},  
  month           = {Jul.},
  volume={},  
  number={},  
  pages={1-1},  
  keywords={},  
  doi={10.1109/JSAC.2020.3041404},  
  ISSN={1558-0008}
}

@article{ref_29_defense,
  title={Robust federated learning in a heterogeneous environment},
  author={Ghosh, Avishek and Hong, Justin and Yin, Dong and Ramchandran, Kannan},
  journal={arXiv preprint arXiv:1906.06629},
  year={2019},
  month           = {Jun.}
}

@INPROCEEDINGS{ref_30_defense,  
  author={Sattler, Felix and Müller, Klaus-Robert and Wiegand, Thomas and Samek, Wojciech},  
  booktitle={ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},   
  title={On the Byzantine Robustness of Clustered Federated Learning},   
  year={2020}, 
  month={May. 4-8},  
  volume={},  
  number={},  
  pages={8861-8865},  
  doi={10.1109/ICASSP40776.2020.9054676}
}

@article{ref_31_defense,
  title={Towards realistic byzantine-robust federated learning},
  author={Portnoy, Amit and Hendler, Danny},
  journal={arXiv preprint arXiv:2004.04986},
  year={2020},
  month           = {Apr.}
}

@article{ref_32_defense,
  title={Byzantine-robust federated machine learning through adaptive model averaging},
  author={Mu{\~n}oz-Gonz{\'a}lez, Luis and Co, Kenneth T and Lupu, Emil C},
  journal={arXiv preprint arXiv:1909.05125},
  year={2019},
  month           = {Sep.}
}

@ARTICLE{ref_33_privacy,  
  author={Wei, Kang and Li, Jun and Ding, Ming and Ma, Chuan and Yang, Howard H. and Farokhi, Farhad and Jin, Shi and Quek, Tony Q. S. and Poor, H. Vincent},  
  journal={IEEE Transactions on Information Forensics and Security},   
  title={Federated Learning With Differential Privacy: Algorithms and Performance Analysis},   
  year={2020},  
  month           = {Apr.},
  volume={15},  
  number={},  
  pages={3454-3469},  
  doi={10.1109/TIFS.2020.2988575}
}

@ARTICLE{ref_34_VerifyNet,  
  author={Xu, Guowen and Li, Hongwei and Liu, Sen and Yang, Kan and Lin, Xiaodong},  
  journal={IEEE Transactions on Information Forensics and Security},   
  title={VerifyNet: Secure and Verifiable Federated Learning},   
  year={2020},  
  month           = {Jul.},
  volume={15},  
  number={},  
  pages={911-926},  
  doi={10.1109/TIFS.2019.2929409}
}

@ARTICLE{ref_35_Byzantine,  author={Abrardo, Andrea and Barni, Mauro and Kallas, Kassem and Tondi, Benedetta},  journal={IEEE Transactions on Information Forensics and Security},   title={A Game-Theoretic Framework for Optimum Decision Fusion in the Presence of Byzantines},   year={2016}, month={Feb.},  volume={11},  number={6},  pages={1333-1345},  doi={10.1109/TIFS.2016.2526963}}

@ARTICLE{ref_36_Byzantine,  author={Wei, Chun-Yi and Chen, Po-Ning and Han, Yunghsiang S. and Varshney, Pramod K.},  journal={IEEE Transactions on Information Forensics and Security},   title={Local Threshold Design for Target Localization Using Error Correcting Codes in Wireless Sensor Networks in the Presence of Byzantine Attacks},   year={2017}, month={Feb.},  volume={12},  number={7},  pages={1571-1584},  doi={10.1109/TIFS.2017.2670531}}

@ARTICLE{ref_37_Byzantine,  author={Liu, Xiang and Lim, Teng Joon and Huang, Jie},  journal={IEEE Transactions on Information Forensics and Security},   title={Optimal Byzantine Attacker Identification Based on Game Theory in Network Coding Enabled Wireless Ad Hoc Networks},   year={2020}, month={Feb.},  volume={15},  number={},  pages={2570-2583},  doi={10.1109/TIFS.2020.2972129}}

@ARTICLE{ref_38_Byzantine,  author={Cao, Ruohan and Wong, Tan F. and Lv, Tiejun and Gao, Hui and Yang, Shaoshi},  journal={IEEE Transactions on Information Forensics and Security},   title={Detecting Byzantine Attacks Without Clean Reference},   year={2016}, month={Jul.},  volume={11},  number={12},  pages={2717-2731},  doi={10.1109/TIFS.2016.2596140}}

@ARTICLE{ref_39_Byzantine,  author={Wang, Cong and Wang, Qian and Ren, Kui and Cao, Ning and Lou, Wenjing},  journal={IEEE Transactions on Services Computing},   title={Toward Secure and Dependable Storage Services in Cloud Computing},   year={2012}, month={May}, volume={5},  number={2},  pages={220-232},  doi={10.1109/TSC.2011.24}}

@ARTICLE{ref_40_Byzantine,  author={Amir, Yair and Danilov, Claudiu and Dolev, Danny and Kirsch, Jonathan and Lane, John and Nita-Rotaru, Cristina and Olsen, Josh and Zage, David},  journal={IEEE Transactions on Dependable and Secure Computing},   title={Steward: Scaling Byzantine Fault-Tolerant Replication to Wide Area Networks},   year={2010}, month={Sep.}, volume={7},  number={1},  pages={80-93},  doi={10.1109/TDSC.2008.53}}

@ARTICLE{ref_41_reputation,  author={Li, Beibei and Lu, Rongxing and Wang, Wei and Choo, Kim-Kwang Raymond},  journal={IEEE Transactions on Information Forensics and Security},   title={{DDOA}: A Dirichlet-Based Detection Scheme for Opportunistic Attacks in Smart Grid Cyber-Physical System},   year={2016}, month={Jun.},  volume={11},  number={11},  pages={2415-2425},  doi={10.1109/TIFS.2016.2576898}}

@ARTICLE{ref_42_FLApp,  author={Li, Beibei and Wu, Yuhao and Song, Jiarui and Lu, Rongxing and Li, Tao and Zhao, Liang},  journal={IEEE Transactions on Industrial Informatics},   title={{DeepFed}: Federated Deep Learning for Intrusion Detection in Industrial Cyber–Physical Systems},   year={2021}, month={Sep.},  volume={17},  number={8},  pages={5615-5624},  //doi={10.1109/TII.2020.3023430}}

@ARTICLE{ref_43_FLApp,  author={Kong, Qinglei and Yin, Feng and Lu, Rongxing and Li, Beibei and Wang, Xiaohong and Cui, Shuguang and Zhang, Ping},  journal={IEEE Transactions on Industrial Informatics},   title={Privacy-Preserving Aggregation for Federated Learning-Based Navigation in Vehicular Fog},   year={2021}, month={Apr.},  volume={},  number={},    //doi={10.1109/TII.2021.3075683}, //note = {doi: {10.1109/TII.2021.3075683}}}

@book{ref_44_reputation,
  title={Detection of False Data Injection Attacks in Smart Grid Cyber-Physical Systems},
  author={Li, Beibei and Lu, Rongxing and Xiao, Gaoxi},
  year={2020},
  publisher={Springer}
}

@ARTICLE{ref_45_defense,  
  author={Liu, Xiaoyuan and Li, Hongwei and Xu, Guowen and Chen, Zongqi and Huang, Xiaoming and Lu, Rongxing},  
  journal={IEEE Transactions on Information Forensics and Security},   
  title={Privacy-Enhanced Federated Learning Against Poisoning Adversaries},   
  year={2021},  
  volume={16},  
  number={},  
  pages={4574-4588},  
  doi={10.1109/TIFS.2021.3108434}
}